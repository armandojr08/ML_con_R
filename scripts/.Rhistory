ylab('f(x)') +
xlab('x') +
scale_x_continuous(limits = c(-15,15)) +
geom_vline(xintercept = 3, color = "ligthblack")
plt_03
plt_03 <- ggplot() +
stat_function(fun=dlogis,
args=list(alfa, beta),
xlim = c(-12,12),
color='blue') +
annotate(geom = "text",
x = 3,
y = 0.0575,
label = TeX("$\\alpha$=3,$\\beta$=4"),
color = "blue",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta + 1),
xlim = c(-12,12),
color = 'red') +
annotate(geom = "text",
x = 3,
y = 0.045,
label = TeX("$\\alpha$=3,$\\beta$=5"),
color = "red",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta - 1),
xlim = c(-12,12),
color = 'green') +
annotate(geom = "text",
x = 3,
y = 0.075,
label = TeX("$\\alpha$=3,$\\beta$=3"),
color = "green",
parse = T) +
stat_function(fun = dnorm,
args = list(alfa,4),
xlim = c(-12,12),
color = 'brown') +
annotate(geom = "text",
x = 3,
y = 0.09,
label = TeX("$\\mu$=3,$\\sigma$=4"),
color = "brown",
parse = T) +
ylab('f(x)') +
xlab('x') +
scale_x_continuous(limits = c(-15,15)) +
geom_vline(xintercept = 3, color = "#CCC")
plt_03
geom_vline(xintercept = 3, color = ""#CC6666"")
plt_03 <- ggplot() +
plt_03 <- ggplot() +
stat_function(fun=dlogis,
args=list(alfa, beta),
xlim = c(-12,12),
color='blue') +
annotate(geom = "text",
x = 3,
y = 0.0575,
label = TeX("$\\alpha$=3,$\\beta$=4"),
color = "blue",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta + 1),
xlim = c(-12,12),
color = 'red') +
annotate(geom = "text",
x = 3,
y = 0.045,
label = TeX("$\\alpha$=3,$\\beta$=5"),
color = "red",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta - 1),
xlim = c(-12,12),
color = 'green') +
annotate(geom = "text",
x = 3,
y = 0.075,
label = TeX("$\\alpha$=3,$\\beta$=3"),
color = "green",
parse = T) +
stat_function(fun = dnorm,
args = list(alfa,4),
xlim = c(-12,12),
color = 'brown') +
annotate(geom = "text",
x = 3,
y = 0.09,
label = TeX("$\\mu$=3,$\\sigma$=4"),
color = "brown",
parse = T) +
ylab('f(x)') +
xlab('x') +
scale_x_continuous(limits = c(-15,15)) +
geom_vline(xintercept = 3, color = "#CC6666")
plt_03
plt_03 <- ggplot() +
stat_function(fun=dlogis,
args=list(alfa, beta),
xlim = c(-12,12),
color='blue') +
annotate(geom = "text",
x = 3,
y = 0.0575,
label = TeX("$\\alpha$=3,$\\beta$=4"),
color = "blue",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta + 1),
xlim = c(-12,12),
color = 'red') +
annotate(geom = "text",
x = 3,
y = 0.045,
label = TeX("$\\alpha$=3,$\\beta$=5"),
color = "red",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta - 1),
xlim = c(-12,12),
color = 'green') +
annotate(geom = "text",
x = 3,
y = 0.075,
label = TeX("$\\alpha$=3,$\\beta$=3"),
color = "green",
parse = T) +
stat_function(fun = dnorm,
args = list(alfa,4),
xlim = c(-12,12),
color = 'brown') +
annotate(geom = "text",
x = 3,
y = 0.09,
label = TeX("$\\mu$=3,$\\sigma$=4"),
color = "brown",
parse = T) +
ylab('f(x)') +
xlab('x') +
scale_x_continuous(limits = c(-15,15)) +
geom_vline(xintercept = 3, color = "#9999CC")
plt_03
plt_03 <- ggplot() +
stat_function(fun=dlogis,
args=list(alfa, beta),
xlim = c(-12,12),
color='blue') +
annotate(geom = "text",
x = 3,
y = 0.0575,
label = TeX("$\\alpha$=3,$\\beta$=4"),
color = "blue",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta + 1),
xlim = c(-12,12),
color = 'red') +
annotate(geom = "text",
x = 3,
y = 0.045,
label = TeX("$\\alpha$=3,$\\beta$=5"),
color = "red",
parse = T) +
stat_function(fun = dlogis,
args = list(alfa, beta - 1),
xlim = c(-12,12),
color = 'green') +
annotate(geom = "text",
x = 3,
y = 0.075,
label = TeX("$\\alpha$=3,$\\beta$=3"),
color = "green",
parse = T) +
stat_function(fun = dnorm,
args = list(alfa,4),
xlim = c(-12,12),
color = 'brown') +
annotate(geom = "text",
x = 3,
y = 0.09,
label = TeX("$\\mu$=3,$\\sigma$=4"),
color = "brown",
parse = T) +
ylab('f(x)') +
xlab('x') +
scale_x_continuous(limits = c(-15,15)) +
geom_vline(xintercept = 3, color = "#9999CC",show.legend = T)
plt_03
7uj}
library(rmarkdown)
knitr::opts_chunk$set(echo = TRUE)
# Debemos hallar P[X>50]
pbinom(50,200,0.3)
# Debemos hallar P[X>50]
pbinom(50,200,0.3, lower.tail = T)
# Debemos hallar P[X>50]
pbinom(50,200,0.3, lower.tail = TF)
# Debemos hallar P[X>50]
pbinom(50,200,0.3, lower.tail = F)
# Debemos hallar P[X>50]
1-pbinom(50,200,0.3)
# SOLUCIÓN
# Sea X la variable que denota el número de clientes morosos en la muestra de n = 200. Entonces X ~ Bin(200,0.3)
n <- 200
prop <- 0.3
# Si aplicamos el teorema central del límite.
media <- n*prop
sd <- sqrt(n*prop*(1-prop))
media
sd
c(media,sd)
c(media,sd)
# entonces los parámetros son: media = 60, desviación estandar = 6.48
# Definimos a la variable Z como:
Z <- (50-media)/sd
Z
# entonces los parámetros son: media = 60, desviación estandar = 6.48
# Definimos a la variable Z como:
Z <- (50-media)/(sd/sqrt(n))
Z
# entonces los parámetros son: media = 60, desviación estandar = 6.48
# Definimos a la variable Z como:
Z <- (50-media)/sd
Z
10/6.48
Z
# Hallaremos P[Z>-1.54]
1-pnorm(-1.54)
# Comparando ambas probabilidades
prob1
library(ggplot2)
plot1 <- ggplot() +
stat_function(fun = dbinom,
args = list(n,prop),
xlim = c(0,400),
color = "red")
plot1 <- ggplot() +
stat_function(fun = dbinom,
args = list(n,prop),
xlim = c(0,400),
plot1                color = "red")
plot1 <- ggplot() +
stat_function(fun = dbinom,
args = list(n,prop),
xlim = c(0,400),
color = "red")
plot1
plot(dbinom)
df <- tibble(x=seq(0, n))
df <- data.frame(x=seq(0, n))
df$p <- dbinom(df$x, n, p)
library(tidyverse)
df <- tibble(x=seq(0, n))
df$p <- dbinom(df$x, n, p)
df$p <- dbinom(df$x, n, prop)
plot1 <- ggplot(df, aes(x=x, y=p)) +
geom_bar(stat='identity', fill='lightblue') +
scale_x_continuous(breaks = 0:n)
plt
plot1
plot2 <- ggplot() +
stat_function(fun=dnorm,
args=list(0,1),
xlim = c(-200,200),
color='brown')
plot2
plot1
plot2 <- ggplot() +
stat_function(fun=dnorm,
args=list(media,prop),
xlim = c(-200,200),
color='brown')
plot2
rm(list = ls())
setwd()
setwd()
getwd()
setwd("C:/Users/USUARIO/Desktop/APRENDIZAJE - ARMANDO/EDUCATE CONSULTORES/MACHINE_LEARNING_CON_R/scripts")
getwd()
url <- "https://raw.githubusercontent.com/robintux/Datasets4StackOverFlowQuestions/master/employees.csv"
data1 <- read.csv(url)
View(data1)
# Librerías
library(dplyr)
library(ggplot2)
library(tidyverse)
library(naniar)
library(simputation)
sessionInfo()
sessionInfo()
View(data1)
str(data1)
# En el dataset, se ven observaciones en blanco, NA, ?, NaN, na
glimpse(data1)
# Tuberías de dplyr/tidyverse
data1 %>%
miss_scan_count(search = list("n.a","na"))
?miss_scan_count
miss_scan_count(data1, search = list("n.a","na"))
# Tuberías de dplyr/tidyverse
data1 %>%
miss_scan_count(search = list("n.a","na,NaN,"?))
# Tuberías de dplyr/tidyverse
data1 %>%
miss_scan_count(search = list("n.a","na,NaN,"?))
# Tuberías de dplyr/tidyverse
data1 %>%
miss_scan_count(search = list("n.a","na","?"))
# Tuberías de dplyr/tidyverse
data1 %>%
miss_scan_count(search = list("n.a","na","?","NaN"))
# Tuberías de dplyr/tidyverse
data1 %>%
miss_scan_count(search = list("n.a","na","?",NaN))
# Tuberías de dplyr/tidyverse
data1 %>%
miss_scan_count(search = list("n.a","na"))
common_na_numbers
common_na_strings
miss_scan_count(data1, search = common_na_strings)
x <- c(1,3,NA,12,7,NA)
y <- c(78,32,NA,12,27,90)
df1 <- data.frame(x,y)
1
df1
miss_scan_count(df1, search = common_na_strings)
z <- c(NA,NA,NA,NA,12,11)
df1 <- data.frame(x,y,z)
df1
miss_scan_count(df1, search = common_na_strings)
miss_scan_count(data1, search = common_na_strings)
# ¿qué hace la función miss_scan_count"
x <- c("Luis","3",NA,"Ana","Romeo",NA)
y <- c("78","32",NA,"12","27","90")
z <- c(NA,NA,NA,NA,"12","11")
df1 <- data.frame(x,y,z)
df1
miss_scan_count(df1, search = common_na_strings)
# ¿qué hace la función miss_scan_count"
x <- c("Luis","3",NA,"Anamaria","Romeo",NA)
y <- c("78","32",NA,"12","27","90")
z <- c(NA,NA,NA,NA,"12","11")
df1 <- data.frame(x,y,z)
df1
miss_scan_count(df1, search = common_na_strings)
w <- c("si","no","si","no","si","si")
# ¿qué hace la función miss_scan_count"
x <- c("Luis","3",NA,"Anamaria","Romeo",NA)
y <- c("78","32",NA,"12","27","90")
v <- c(T,T,F,F,F,T)
w <- c("si","no","si","no","si","si")
z <- c(NA,NA,NA,NA,"12","11")
df1 <- data.frame(x,y,z,w,v)
df1
miss_scan_count(df1, search = common_na_strings)
v <- c(T,T,F,F,NA,T)
w <- c("si","no","si","no","si","si")
z <- c(NA,NA,NA,NA,"12","11")
df1 <- data.frame(x,y,z,w,v)
df1
miss_scan_count(df1, search = common_na_strings)
common_na_strings
outpoutNA <- miss_scan_count(data1, search = common_na_strings)
# Funciones para manejos de NA
?replace_with_na()
# Funciones para manejos de NA
# replace_with_na()     reemplaza valores epecíficos con NA
# replace_with_na_all() todas las variables
# replace_with_na_at()  especificamos/seleccionamos un subconj de variables
# replace_with_na_if()  rellenamos bajo alguna condicion
colnames(data1)
data1 %>%
replace_with_na(replace = list(Team = c('na','n.a'))) %>%
miss_scan_count(search = common_na_strings)
outpoutNA
# Buscamos los espacios en blanco o vacíos
data1 %>%
replace_with_na_all(condition = ~.x == "") %>%
miss_scan_count(search = common_na_strings)
# Reemplazamos todos los posibles valores de common_na_strngs
# por NA
data1 %>%
replace_with_na_all(condition = ~.x %in% common_na_strings) %>%
miss_scan_count(search = common_na_strings)
df1
miss_scan_count(df1, search = common_na_strings)
# ¿qué hace la función miss_scan_count"
x <- c("Luis","3",NA,"Anamaria","Romeo",NA)
y <- c("78","32",NA,"n.a","27","n.a")
v <- c(T,T,F,F,NA,T)
w <- c("si","no","si","na","si","si")
z <- c(NA,NA,NA,NA,"12","11")
df1 <- data.frame(x,y,z,w,v)
df1
miss_scan_count(df1, search = common_na_strings)
# Reemplazamos todos los posibles valores de common_na_strngs
# por NA
data1 %>%
replace_with_na_all(condition = ~.x %in% common_na_strings) %>%
miss_scan_count(search = common_na_strings)
common_na_strings
# Analizando otro dataset más sencillo
data("pedestrian")
View(pedestrian)
# Exploremos pedestrian en busca de N/A
miss_scan_count(pedestrian, search = list("N/A"))
str(pedestrian)
# Exploremos pedestrian en busca de missing
miss_scan_count(pedestrian, search = list("missing"))
miss_scan_count(pedestrian, search = list("na"))
miss_scan_count(pedestrian, search = list("n.a"))
miss_scan_count(pedestrian, search = list(""))
miss_scan_count(pedestrian, search = list(" "))
miss_scan_count(pedestrian, search = list(" "))
#
pollerias <- c("A la leña"," El Meson", "Norkys")
#
pollerias <- c("A la leña"," El Meson", "Norkys", "Pio Pio", "Rockys")
ventas_al_dia <- c(1200,1800,1240,2000,"")
df_polleria <- data.frame(pollerias, ventas_al_dia)
df_polleria
str(df_polleria)
miss_scan_count(df_polleria, search = list(""))
miss_scan_count(df_polleria, search = list(" "))
miss_scan_count(df_polleria, search = list(""))
#
pollerias <- c("A la leña"," El Meson", "Norkys", "Pio Pio", "Rockys")
ventas_al_dia <- c(1200,1800,1240,2000,"na")
df_polleria <- data.frame(pollerias, ventas_al_dia)
df_polleria
str(df_polleria)
miss_scan_count(df_polleria, search = list(""))
miss_scan_count(df_polleria, search = list("na"))
# realmente, ¿qué hace miss_scan_count()
pollerias <- c("A la leña"," El Meson", "Norkys", "Pio Pio", "Rockys", "N/A")
ventas_al_dia <- c(1200,1800,1240,2000,"na", 1300)
df_polleria
# realmente, ¿qué hace miss_scan_count()
pollerias <- c("A la leña"," El Meson", "Norkys", "Pio Pio", "Rockys", "N/A")
ventas_al_dia <- c(1200,1800,1240,2000,"na", 1300)
df_polleria <- data.frame(pollerias, ventas_al_dia)
df_polleria
str(df_polleria)
miss_scan_count(df_polleria, search = list("na"))
miss_scan_count(df_polleria, search = list("na", "N/A"))
common_na_strings
miss_scan_count(df_polleria, search = common_na_strings)
?search()
miss_scan_count(df_polleria, search = common_na_strings[-22])
ventas_al_dia <- c(1200,1800,1240,2000,"na", 1300, NA)
df_polleria <- data.frame(pollerias, ventas_al_dia)
df_polleria
str(df_polleria)
miss_scan_count(df_polleria, search = list("na", "N/A"))
miss_scan_count(df_polleria, search = common_na_strings)
miss_scan_count(df_polleria, search = common_na_strings[-22])
# busquemos reemplazar los "", "na, "n.a", "NaN"
data1_limpia <- replace_with_na(data1,
replace = list(Team = c("","na","n.a","NaN"),
Bonus.. = c("","na","n.a","NaN")))
miss_scan_count(data1_limpia, search = list("","na","n.a","NaN"))
View(data1_limpia)
# replace_with_na_at para reemplazar con NA
replace_with_na_at(data1,
.vars = c("Fist.Name","Gender","Team"),
~.x %in% c("","na","n.a","NaN"))
# replace_with_na_at para reemplazar con NA
replace_with_na_at(data1,
.vars = c("Fist.Name","Gender","Team"),
~.x %in% c("","na","n.a","NaN","?"))
# Veamos un ejemplo con replace_with_na_if con la condición
# de que el valor sea un caracter
replace_with_na_if(data1,
.predicate = is.character,
~.x %in% c(""," ","na","NaN","?"))
?replace_with_na_if()
condition = ~.x %in% c(""," ","na","NaN","?")
condition = ~.x %in% c(""," ","na","NaN","?")
a
# usando el replace_with_na_all
replace_with_na_all(data1,
condition = ~.x %in% c(""," ","na","NaN","?"))
# usando el replace_with_na_all
replace_with_na_all(data1,
condition = ~.x %in% c(""," ","na","NaN","?","n.a","n.a."))
# creando un dataframe que no contenga caracteres extraños
data1_limpia_2 <- replace_with_na_all(data1,
condition = ~.x %in% c(""," ","na","NaN","?","n.a","n.a."))
View(data1_limpia_2)
str(data1_limpia_2)
# modificar el tipo de variables salary y bonus..
data1_limpia_2$Salary <- as.numeric(data1_limpia_2$Salary)
data1_limpia_2$Bonus.. <- as.numeric(data1_limpia_2$Bonus..)
data1_limpia_2$Senior.Management <- as.logical(data1_limpia_2$Senior.Management)
str(data1_limpia_2)
"" %in% "los"
"" %in% "los "
2los "
"los "
"los " %in% ""
c("", " ")
"los " in c("", " ")
"los " %in% c("", " ")
"" %in% c("", " ")
" " %in% c("", " ")
# visualizacion de NA
vis_miss(data1_limpia_2)
# visualizacion de NA
vis_miss(data1_limpia_2)
